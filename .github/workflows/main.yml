name: Daily Web Scraping

on:
  schedule:
    - cron: '0 3 * * *'  # Runs every day at midnight UTC
  workflow_dispatch:  # Allows manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest
    environment: FIREBASE_CREDENTIALS

    steps:
      # Check out the repository code
      - name: Checkout code
        uses: actions/checkout@v4

      # Set up Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'  # Adjust if you need a different version

      # Install Chrome and dependencies
      - name: Install Chrome and dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable unzip jq

      # Get Chrome version
      - name: Get Chrome version
        run: |
          CHROME_VERSION=$(google-chrome --version | grep -oE '[0-9]+\.[0-9]+\.[0-9]+')
          echo "CHROME_VERSION=$CHROME_VERSION" >> $GITHUB_ENV

      # Install ChromeDriver matching Chrome version
      - name: Install ChromeDriver
        run: |
          # Use the major version of Chrome to find a compatible ChromeDriver
          CHROME_MAJOR_VERSION=$(echo "$CHROME_VERSION" | cut -d'.' -f1)
          CHROMEDRIVER_VERSION=$(curl -sS "https://chromedriver.storage.googleapis.com/LATEST_RELEASE_${CHROME_MAJOR_VERSION}")
          if [ -z "$CHROMEDRIVER_VERSION" ]; then
            echo "Error: Could not find ChromeDriver version for Chrome major version $CHROME_MAJOR_VERSION"
            exit 1
          fi
          echo "Instalando ChromeDriver vers√£o $CHROMEDRIVER_VERSION"
          wget -q "https://storage.googleapis.com/chrome-for-testing-public/$CHROMEDRIVER_VERSION/linux64/chromedriver-linux64.zip"
          unzip chromedriver-linux64.zip
          sudo mv chromedriver-linux64/chromedriver /usr/bin/chromedriver
          sudo chmod +x /usr/bin/chromedriver
          chromedriver --version

      # Install Python dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 firebase-admin selenium

      # Download Firebase credentials from raw URL stored in secrets
      - name: Download Firebase credentials
        run: |
          curl -H "Authorization: token ${{ secrets.TOKEN }}" \
               -H "Accept: application/vnd.github.v3.raw" \
               -o firebase_credentials.json \
               https://api.github.com/repos/marcospaulor/secret-json-firebase/contents/servicos-ufcat-app-firebase-adminsdk-wf4o4-7becca3684.json
               
      # Run the scraping script
      - name: Run scraping script
        run: python main.py

      # Optional: Clean up credentials file
      - name: Clean up
        if: always()
        run: rm -f firebase_credentials.json
