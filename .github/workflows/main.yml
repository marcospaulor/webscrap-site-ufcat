name: Daily Web Scraping

on:
  schedule:
    - cron: '0 3 * * *' # Executa todos os dias à meia-noite UTC
  workflow_dispatch: # Permite executar manualmente pelo GitHub

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      # Faz checkout do código do repositório
      - name: Checkout repository
        uses: actions/checkout@v4

      # Configura o ambiente Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      # Install Chrome and ChromeDriver
      - name: Install Chrome and ChromeDriver
        run: |
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          CHROME_VERSION=$(google-chrome --version | grep -oE '[0-9]+.[0-9]+.[0-9]+')
          MAJOR_VERSION=$(echo $CHROME_VERSION | cut -d. -f1)
          wget "https://chromedriver.storage.googleapis.com/LATEST_RELEASE_$MAJOR_VERSION" -O chromedriver_version
          CHROMEDRIVER_VERSION=$(cat chromedriver_version)
          wget "https://chromedriver.storage.googleapis.com/$CHROMEDRIVER_VERSION/chromedriver_linux64.zip"
          unzip chromedriver_linux64.zip
          sudo mv chromedriver /usr/bin/chromedriver
          sudo chmod +x /usr/bin/chromedriver

      # Instala dependências do Python
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Executa o script Python
      - name: Run Python script
        env:
          FIREBASE_CREDENTIALS: ${{ secrets.FIREBASE_CREDENTIALS }}
        run: |
          echo "$FIREBASE_CREDENTIALS" > ./database/servicos-ufcat-app-firebase-adminsdk-wf4o4-7becca3684.json
          python main.py
